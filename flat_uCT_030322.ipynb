{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import math as m\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import iqr, kurtosis, skew\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "#import pillow (PIL) to allow for image cropping\n",
    "import PIL \n",
    "from PIL import Image, ImageChops\n",
    "from io import BytesIO\n",
    "\n",
    "#image simplification and priming\n",
    "#Convolution libraries\n",
    "from scipy import signal\n",
    "from skimage.measure import label, regionprops\n",
    "from sklearn.preprocessing import Binarizer\n",
    "#from sklearn.preprocessing import Binarizer\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "#Skimage used for direct detection ellipse\n",
    "from skimage import io\n",
    "from skimage import data, color, img_as_ubyte\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import canny\n",
    "from skimage.transform import hough_ellipse\n",
    "from skimage.draw import ellipse_perimeter\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "#Skimage used for direct detection circles\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from skimage.feature import canny\n",
    "from skimage.draw import circle_perimeter\n",
    "\n",
    "#OpenCV for circle detection\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This allows for the cutting of black space from each uCT image\n",
    "def trim2(im,padding,offset):\n",
    "    #selecting the outermost pixels \n",
    "    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n",
    "    diff = ImageChops.difference(im, bg)\n",
    "    diff = ImageChops.add(diff, diff, 2.0, offset)\n",
    "    bbox = diff.getbbox()\n",
    "    #adding small boarder to each image \n",
    "    bbox = np.array(bbox).reshape(2,2)\n",
    "    bbox[0] -= padding\n",
    "    bbox[1] += padding\n",
    "    bbox = bbox.flatten()\n",
    "    bbox = tuple(bbox)\n",
    "    if bbox:\n",
    "        return bbox,padding\n",
    "\n",
    "#obscure convolutes 2D arrays with a (x,y) sized screen screen and then binarizes them\n",
    "def obscure(image_array,x,y,invert):\n",
    "    screen = np.ones((x,y), dtype=int) \n",
    "    image_array = signal.convolve2d(image_array,screen, mode='same') #,mode='same')\n",
    "    #convert image into binary\n",
    "    #image_array = np.where(image_array > 127.5, 1, 0)\n",
    "    if invert == 'yes':\n",
    "        image_array = np.where(image_array > 127.5, 0, 1)\n",
    "    elif invert == 'no':\n",
    "        image_array = np.where(image_array > 127.5, 1, 0)\n",
    "    return image_array\n",
    "\n",
    "#This allows for the additon of a padding to numpy array - useful for adding boarders to images\n",
    "#found: https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html\n",
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 10)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value\n",
    "    return vector\n",
    "    \n",
    "def reject_outliers(data, m = 2):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d/int(mdev) if mdev else 0\n",
    "    return data[s<m]\n",
    "\n",
    "##Create file if does not exist\n",
    "def checkdir(dir):\n",
    "    #First check if directory exists\n",
    "    if os.path.isdir(dir) == False:\n",
    "        os.makedirs(dir)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation of data read\n",
    "#current location\n",
    "location = os.getcwd()\n",
    "\n",
    "#where is data located    \n",
    "loc = '/Volumes/RISTO_EXHDD/uCT'\n",
    "# loc = '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/hollow_fibre'\n",
    "# loc = '/Volumes/Ristos_SSD/uCT'\n",
    "\n",
    "#What is the name of the data set?\n",
    "data_set = 'S4_50PPM_8HRS_5PX'#'S4_10PPM_03_5PX_1_Rec'\n",
    "\n",
    "data_loc = loc+'/'+data_set+'/'+data_set+'_Rec2'\n",
    "\n",
    "# data_loc = loc+'/'+'test'+'/'\n",
    "#location for saved data\n",
    "save_loc = '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/flat_sheet/output/'\n",
    "# save_loc = r'C:\\Users\\Alex Witt\\Documents\\Python_Analysis\\Outputs'\n",
    "\n",
    "#Check that the save location exists\n",
    "checkdir(save_loc)\n",
    "\n",
    "#what to name to save files\n",
    "savename = data_set\n",
    "\n",
    "#initilisation of constants\n",
    "#Set conversion of px to um\n",
    "pxum = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Image processing script as function to be entered into multiprocessing\n",
    "def fibrefeature(dat_loc,filename,pxum,fibre_pad,fibre_scale,img_no,rotate,debug,debug_print,save_pic):\n",
    "    #check whether to save picture or not\n",
    "    save_pic = save_pic\n",
    "    #Intially open full image\n",
    "    im = Image.open(dat_loc+'/'+filename)\n",
    "    #check if file needs converting\n",
    "    if im.mode == 'I;16':\n",
    "        #specifying its sampling mode\n",
    "        im.mode = 'I'\n",
    "        #convert the mode into 'L' (8-bit pixels, black and white) and save as temporary file\n",
    "        im = im.point(lambda i:i*(1./256)).convert('L')\n",
    "        #open temporaray file\n",
    "        #im = Image.open('temp.jpeg')\n",
    "    elif im.mode == 'RGB' or im.mode == 'RGBA':\n",
    "        im = im.convert('L')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    #Once image is opened make copies of unedited image and array to use later on\n",
    "    #make copy of original unadultorated image\n",
    "    im_orig = im.copy()\n",
    "    #as well as an array of the unadultorated image\n",
    "    im_orig_array = np.array(im_orig)\n",
    "    #A = (A * B)\n",
    "    #im_orig_array = im_orig_array*(255.0/im_orig_array.max())\n",
    "    \n",
    "    im_orig_array = im_orig_array.astype(\"uint8\")\n",
    "    \n",
    "    #create plot of convoluted and binarised image\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(im_orig_array, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'raw_image.png', dpi=300)\n",
    "            \n",
    "    ##Make selection of top RHS to find average pixel value to subtract\n",
    "    bg_x1 = round((0.90*im_orig_array.shape[1]))\n",
    "    bg_x2 = round((0.99*im_orig_array.shape[1]))\n",
    "    bg_y1 = round((0.90*im_orig_array.shape[0]))\n",
    "    bg_y2 = round((0.99*im_orig_array.shape[0]))\n",
    "    \n",
    "    # print(bg_x1)\n",
    "    # print(bg_x2)\n",
    "    # print(bg_y1)\n",
    "    # print(bg_y2)\n",
    "    \n",
    "    bg_select = im_orig_array[bg_y1:bg_y2,bg_x1:bg_x2]\n",
    "    # print(bg_select)\n",
    "    \n",
    "    # bg_select_df = pd.DataFrame(bg_select)\n",
    "    # bg_select_df.to_csv(save_loc+savename+'bg_select.csv')\n",
    "\n",
    "#     ret4,bg_select = cv2.threshold(im_orig_array,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    #create plot selected image background\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(bg_select, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'_bg_select.png', dpi=300)\n",
    "    \n",
    "    # height, width = bg_select.shape\n",
    "    # bg_med = []\n",
    "    # for i in range(0, width):\n",
    "    #     #temp = (bg_select[i,:] > 0.1) * bg_select[i,:]\n",
    "    #     temp = bg_select[i,:][bg_select[i,:]!=0]\n",
    "    #     bg_med.extend(temp)\n",
    "    \n",
    "    bg_med = bg_select.flatten()\n",
    "\n",
    "    #print(bg_med)\n",
    "    bg_select_med = np.median(bg_med)+2*np.std(bg_med)  \n",
    "    bg_select_mean = np.mean(bg_med)+2*np.std(bg_med)\n",
    "    \n",
    "    im_orig_array_c = im_orig_array.copy()\n",
    "    \n",
    "    #ret,bg_select = cv2.threshold(im_orig_array,bg_select_mean,im_orig_array.max(),cv2.THRESH_BINARY)\n",
    "    im_orig_array_c[im_orig_array_c < bg_select_mean] = 0\n",
    "    \n",
    "    #create plot selected image background\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(im_orig_array_c, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'_thresh_bg_select.png', dpi=300)\n",
    "            \n",
    "    im = Image.fromarray(im_orig_array_c)\n",
    "    \n",
    "    \n",
    "    im_debug = np.array(im)\n",
    "    #create plot selected image background\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(im_debug, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'im_debug.png', dpi=300)\n",
    "\n",
    "    #trim image to just pixels of interest using trim as defined above\n",
    "    fibre_box,fpadding = trim2(im,(fibre_pad*2),trim_offset)\n",
    "    im = im.crop(fibre_box)\n",
    "    #convert trimmed image into numpy array\n",
    "    nim =  np.array(im)\n",
    "    #make copy of trimmed image to be used later on if needed\n",
    "    nim_copy = nim.copy()\n",
    "    \n",
    "    #create plot of convoluted and binarised image\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(nim_copy, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'cropped_image.png', dpi=300)\n",
    "    \n",
    "    #Reduce image size\n",
    "    nim = rescale(nim, fibre_scale, anti_aliasing=False)\n",
    "    nim = np.uint8(nim * 255)\n",
    "            \n",
    "############################################################################################################################################################ \n",
    "                                                ### OUTER WALL DETECTION  ###\n",
    "############################################################################################################################################################\n",
    "    \n",
    "    ##-- priming image for further analysis with obscure as defined above\n",
    "    x = 7\n",
    "    y = 7\n",
    "    #Initially applying GayssuanBlur to minimise noise in image\n",
    "    nim = cv2.GaussianBlur(nim,(x,y),0)\n",
    "    #apply OTSU's binarisation method to strip away as much noise as possible and convert image into binary\n",
    "    ret,fibre_thresh = cv2.threshold(nim,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    x = 2\n",
    "    y = 2\n",
    "    #1. Mark all pixels such that there are at least 6 pixels in their 7x7 neighborhood this will become defined as obscure function\n",
    "    nim = signal.convolve2d(fibre_thresh,np.ones((x,y), dtype=int), mode='same')\n",
    "    \n",
    "\n",
    "    #create plot of convoluted and binarised image\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(nim, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'convolve2d_image.png', dpi=300)\n",
    "\n",
    "    #need to find overall orientation of image and rotate to make horizontal\n",
    "    #to initially find orientation to trim image to leave behind only narrow region of interest this must be in both the x and y axis\n",
    "    #to ensure this is only done for first image make if gate to prevent multi runs\n",
    "    coords = 0 \n",
    "    # img_no = 0\n",
    "    if img_no == 0:\n",
    "        #get location of all detected true pixels\n",
    "        coords = np.column_stack(np.where(nim == 255))\n",
    "        # print(coords)\n",
    "        #consider the spread of data in each direction, as considering flat membranes expect smaller spread in direction of normal to the face of the membrane\n",
    "        #find the IQR in x_axis\n",
    "        iqr_x = iqr(coords[:,0])\n",
    "        #find the median in the x-axis\n",
    "        median_x = np.median(coords[:,0])\n",
    "        # #consider data in only y axis\n",
    "        # data = coords[:,0]\n",
    "        #find the IQR in y_axis\n",
    "        iqr_y = iqr(coords[:,1])\n",
    "        #print(iqr_y)\n",
    "        if iqr_x < iqr_y:\n",
    "            #make note to rotate\n",
    "            rotate = 1\n",
    "\n",
    "    if rotate == 1:    \n",
    "        #rotate the image\n",
    "        #th1 = ndimage.rotate(th1, 90,reshape=False )\n",
    "        nim = nim.swapaxes(-2,-1)[...,::-1]\n",
    "        # print(nim)\n",
    "        #get location of all detected true pixels\n",
    "        coords = np.column_stack(np.where(nim == 255))\n",
    "        #reconsier the median of the x axis as that previously of the y axis due to rotation\n",
    "        median_x = np.median(coords[:,0])\n",
    "        #reconsider IQR as well\n",
    "        iqr_x = iqr(coords[:,0])\n",
    "    \n",
    "        \n",
    "        \n",
    "    #create plot of convoluted and binarised image\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(nim, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'rotated_convolve2d_image.png', dpi=300)\n",
    "\n",
    "    #Covert list of coordinates into pandas dataframe\n",
    "    coords = pd.DataFrame(coords)\n",
    "    #get unique y-axis points at which pixels are detected\n",
    "    unique_vals = pd.unique(coords[0].values)\n",
    "    \n",
    "    #Make list to hold all of the membrane thicknesses\n",
    "    thicknesses = []\n",
    "    \n",
    "    #Itterating through each of the unique y-axis points\n",
    "    for i in unique_vals:\n",
    "        #isolate only the data associated with y-axis\n",
    "        temp = coords.loc[coords[0] == i][1]\n",
    "        #Find the median and IQR of each line\n",
    "        Q1 = temp.quantile(0.25)\n",
    "        Q3 = temp.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        median = temp.quantile(0.5)\n",
    "        #convert temp from series to list\n",
    "        temp = temp.tolist()\n",
    "        #remove any values from temp which are more than 2 IQR from median\n",
    "        temp = [x if abs(x-median)<(2*IQR) else median for x in temp]\n",
    "        #find how thick membrane is at each y axis point\n",
    "        if max(temp)-min(temp) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            thicknesses.append(max(temp)-min(temp))\n",
    "    # print(thicknesses)\n",
    "    \n",
    "    #Convert list of thicknesses to an array so that stats may be determined\n",
    "    thicknesses = np.array(thicknesses)\n",
    "    #Calculate the stats associated with membrane thicknesses\n",
    "    thick_mean = np.mean(thicknesses)*(1/fibre_scale)*pxum\n",
    "    thick_med = (np.median(thicknesses)/fibre_scale)*pxum\n",
    "    q75, q25 = (np.percentile(thicknesses, [75 ,25])/fibre_scale)*pxum\n",
    "    thick_IQR = q75 - q25\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "############################################################################################################################################################ \n",
    "                                        ### Save out  ###\n",
    "############################################################################################################################################################\n",
    "    return (thick_mean,thick_med,thick_IQR,rotate)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/7hyg5yn15331npl8_ss6cl_40000gn/T/ipykernel_2035/1193030535.py:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for filename in tqdm_notebook(files):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd06631463f4c6bb0956e5963d61756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         filename  thick_IQR  thick_mean  thick_med\n",
      "0  S4_50PPM_8HRS_5PX__rec0002.tif       40.0  150.851064      160.0\n",
      "1  S4_50PPM_8HRS_5PX__rec0003.tif       20.0  147.741935      160.0\n",
      "2  S4_50PPM_8HRS_5PX__rec0004.tif       40.0  154.594595      160.0\n",
      "3  S4_50PPM_8HRS_5PX__rec0005.tif       40.0  155.957447      160.0\n",
      "4  S4_50PPM_8HRS_5PX__rec0006.tif       40.0  149.723757      160.0\n"
     ]
    }
   ],
   "source": [
    "test = True\n",
    "show_all = False\n",
    "debug_print = False\n",
    "\n",
    "columns = ['filename','thick_IQR','thick_mean','thick_med']\n",
    "\n",
    "cfp = pd.DataFrame(columns = columns)\n",
    "\n",
    "if test == True:\n",
    "    #initilisation of constants - Set conversion of px to um\n",
    "    pxum = 5\n",
    "    wire_diameter = 300\n",
    "    fibre_pad = 50\n",
    "    fibre_scale = 0.25\n",
    "    trim_offset = -80\n",
    "    \n",
    "    #Generate list of file in data location\n",
    "    files = [x for x in os.listdir(data_loc) if x.endswith(('.tif','.jpg','.png','.bmp'))==True and x.startswith('._')==False]\n",
    "    \n",
    "    #Make counter for file number\n",
    "    img_no = -1\n",
    "    rotate = 0\n",
    "    #Itterating through files in data location\n",
    "    for filename in tqdm_notebook(files):     \n",
    "        #proceed image count\n",
    "        img_no = img_no+1 \n",
    "        #acertain fibre properties as defined above\n",
    "        if show_all == True:\n",
    "            print(filename)\n",
    "            flatmem_properties = fibrefeature(data_loc,filename,pxum,fibre_pad,fibre_scale,img_no,rotate,True,True,True)\n",
    "        else:\n",
    "            # print(filename)\n",
    "            flatmem_properties = fibrefeature(data_loc,filename,pxum,fibre_pad,fibre_scale,img_no,rotate,False,False,False)\n",
    "            \n",
    "        if flatmem_properties is None:\n",
    "            pass\n",
    "        else:\n",
    "            # print(flatmem_properties)\n",
    "            rotate = flatmem_properties[3]\n",
    "            cfp = cfp.append({'filename':filename,'thick_mean':flatmem_properties[0],'thick_med':flatmem_properties[1],'thick_IQR':flatmem_properties[2]}, ignore_index=True)\n",
    "    print(cfp.head())\n",
    "    cfp.to_csv(save_loc+savename+'.csv')\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/flat_sheet/output/processed_flat.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dw/7hyg5yn15331npl8_ss6cl_40000gn/T/ipykernel_2035/4086339558.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Initially open processed data csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprocessed_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_loc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'processed_flat.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#For each of the rows in the processed data csv file match the corresponding sample file to associated metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessed_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/flat_sheet/output/processed_flat.csv'"
     ]
    }
   ],
   "source": [
    "#Initially open processed data csv file\n",
    "processed_flat = pd.read_csv(save_loc + 'processed_flat.csv',index_col = 0)\n",
    "\n",
    "#For each of the rows in the processed data csv file match the corresponding sample file to associated metadata\n",
    "for file, row in processed_flat.iterrows():\n",
    "    #processed_flat.iloc[:,0]:\n",
    "    #print(file)\n",
    "    processed_flat.loc[file, 'pyridine_conc'] = sample_key.loc[sample_key['uCT_filename'] == file, 'pyridine_conc'].iloc[0]\n",
    "    processed_flat.loc[file, 'rotation_speed'] = sample_key.loc[sample_key['uCT_filename'] == file, 'rotation_speed'].iloc[0]\n",
    "    processed_flat.loc[file, 'solution_name'] = sample_key.loc[sample_key['uCT_filename'] == file, 'solution_name'].iloc[0]\n",
    "    processed_flat.loc[file, 'time_spun'] = sample_key.loc[sample_key['uCT_filename'] == file, 'time_spun'].iloc[0]\n",
    "    voltage = sample_key.loc[sample_key['uCT_filename'] == file, 'voltage'].iloc[0]\n",
    "    min_voltage = sample_key.loc[sample_key['uCT_filename'] == file, 'min_voltage'].iloc[0]\n",
    "    max_voltage = sample_key.loc[sample_key['uCT_filename'] == file, 'max_voltage'].iloc[0]\n",
    "    processed_flat.loc[file, 'Voltage Range'] = (((voltage-min_voltage)/(max_voltage-min_voltage))*100).round(0)\n",
    "#Having collated all the meta data check correctly recorded\n",
    "print(processed_flat.head())\n",
    "#save pandas data frame as CSV\n",
    "processed_flat.to_csv(save_loc + 'processed_flat.csv')\n",
    "#cdf.to_csv(save_loc+'MicroCT/porosity_data/processed/'+'cdf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initially import processed flat sheet membrane data\n",
    "processed_flat = pd.read_csv(save_loc + 'processed_flat.csv',index_col = 0)\n",
    "\n",
    "#first create figure for new plot of force/extension\n",
    "fig, ax = plt.subplots()\n",
    "                \n",
    "#Before able to plot need to catagorise data by third variable e.g by pyridine conc\n",
    "\n",
    "#as all data is in a single column and are only plotting a line graph can separate series using pandas groupby\n",
    "for key, grp in processed_flat.sort_values(['time_spun']).groupby(['pyridine_conc']):\n",
    "    \n",
    "    #set the data in each axis\n",
    "    x = grp['time_spun']\n",
    "    y = grp['median_thickness_um']\n",
    "\n",
    "    ax.plot(x,y, label = key)\n",
    "    #add precalculated IQR bands for each graph for force/extension line graph\n",
    "    ax.fill_between(grp['time_spun'], grp['median_thickness_um'] - grp['thickness_IQR_um'],grp['median_thickness_um'] + grp['thickness_IQR_um'], alpha=0.35)\n",
    "\n",
    "#adding formatting into each graph\n",
    "#force/extension graph\n",
    "xlabel = 'Time Spun (Hrs)'\n",
    "ylabel = 'Median Membrane Thickness ($\\mu$m)'\n",
    "ax.legend()\n",
    "ax.set(xlabel=xlabel, ylabel= ylabel) #(xlabel=x, ylabel='Fibre Diameter ($\\mu$m)')\n",
    "\n",
    "#save figure out\n",
    "fig.savefig(save_loc+'flat_thickness.png',bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
