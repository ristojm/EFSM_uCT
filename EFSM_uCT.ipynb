{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import math as m\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import iqr, kurtosis, skew\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from statannot import add_stat_annotation\n",
    "\n",
    "#import pillow (PIL) to allow for image cropping\n",
    "import PIL \n",
    "from PIL import Image, ImageChops\n",
    "from io import BytesIO\n",
    "\n",
    "#image simplification and priming\n",
    "#Convolution libraries\n",
    "from scipy import signal\n",
    "from skimage.measure import label, regionprops\n",
    "from sklearn.preprocessing import Binarizer\n",
    "#from sklearn.preprocessing import Binarizer\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "#Skimage used for direct detection ellipse\n",
    "from skimage import io\n",
    "from skimage import data, color, img_as_ubyte\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import canny\n",
    "from skimage.transform import hough_ellipse\n",
    "from skimage.draw import ellipse_perimeter\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "\n",
    "#Skimage used for direct detection circles\n",
    "from skimage.transform import hough_circle, hough_circle_peaks\n",
    "from skimage.feature import canny\n",
    "from skimage.draw import circle_perimeter\n",
    "\n",
    "#OpenCV\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for cutting of blank space from uCT image\n",
    "def trim2(im,padding,offset):\n",
    "    #selecting the outermost pixels \n",
    "    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n",
    "    diff = ImageChops.difference(im, bg)\n",
    "    diff = ImageChops.add(diff, diff, 2.0, offset)\n",
    "    bbox = diff.getbbox()\n",
    "    #adding small boarder to each image \n",
    "    bbox = np.array(bbox).reshape(2,2)\n",
    "    bbox[0] -= padding\n",
    "    bbox[1] += padding\n",
    "    bbox = bbox.flatten()\n",
    "    bbox = tuple(bbox)\n",
    "    if bbox:\n",
    "        return bbox,padding\n",
    "\n",
    "#Define function obscure which convolutes 2D arrays with a (x,y) sized screen screen and then binarizes them\n",
    "def obscure(image_array,x,y,invert):\n",
    "    screen = np.ones((x,y), dtype=int) \n",
    "    image_array = signal.convolve2d(image_array,screen, mode='same') #,mode='same')\n",
    "    #convert image into binary\n",
    "    #image_array = np.where(image_array > 127.5, 1, 0)\n",
    "    if invert == 'yes':\n",
    "        image_array = np.where(image_array > 127.5, 0, 1)\n",
    "    elif invert == 'no':\n",
    "        image_array = np.where(image_array > 127.5, 1, 0)\n",
    "    return image_array\n",
    "\n",
    "#This allows for the additon of a padding to numpy array - useful for adding boarders to images\n",
    "#found: https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html\n",
    "def pad_with(vector, pad_width, iaxis, kwargs):\n",
    "    pad_value = kwargs.get('padder', 10)\n",
    "    vector[:pad_width[0]] = pad_value\n",
    "    vector[-pad_width[1]:] = pad_value\n",
    "    return vector\n",
    "\n",
    "#Define function to remove outlires from dataset\n",
    "def reject_outliers(data, m = 2):\n",
    "    d = np.abs(data - np.median(data))\n",
    "    mdev = np.median(d)\n",
    "    s = d/int(mdev) if mdev else 0\n",
    "    return data[s<m]\n",
    "\n",
    "##Create file if does not exist\n",
    "def checkdir(dir):\n",
    "    #First check if directory exists\n",
    "    if os.path.isdir(dir) == False:\n",
    "        os.makedirs(dir)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialisation of data read\n",
    "#current location\n",
    "location = os.getcwd()\n",
    "\n",
    "#What is the root source of the data to be processed?    \n",
    "loc = '/Volumes/RISTO_EXHDD/uCT'\n",
    "# loc = '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/hollow_fibre'\n",
    "# loc = '/Volumes/Ristos_SSD/uCT'\n",
    "\n",
    "#What is the name of the data set?\n",
    "data_set = 'S4_50PPM_8HRS_5PX'#'S4_10PPM_03_5PX_1_Rec'\n",
    "\n",
    "#Where is the exact data location\n",
    "data_loc = loc+'/'+data_set+'/'+data_set+'_Rec2'\n",
    "\n",
    "#location for saved data\n",
    "save_loc = '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/flat_sheet/output/'\n",
    "\n",
    "#Check that the save location exists\n",
    "checkdir(save_loc)\n",
    "\n",
    "#what to name to save files\n",
    "savename = data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Image processing script as function\n",
    "def fibrefeature(dat_loc,filename,pxum,fibre_pad,fibre_scale,img_no,rotate,debug,debug_print,save_pic):\n",
    "    #check whether to save figures out or not\n",
    "    save_pic = save_pic\n",
    "    \n",
    "    #Open the image\n",
    "    im = Image.open(dat_loc+'/'+filename)\n",
    "    #check if file needs converting\n",
    "    if im.mode == 'I;16':\n",
    "        #specify the image sampling mode\n",
    "        im.mode = 'I'\n",
    "        #convert the mode into 'L' (8-bit pixels, black and white) and save as temporary file\n",
    "        im = im.point(lambda i:i*(1./256)).convert('L')\n",
    "    #If already in RGB or RGBA then can convert directly\n",
    "    elif im.mode == 'RGB' or im.mode == 'RGBA':\n",
    "        im = im.convert('L')\n",
    "    #If image type is not an issue then just continue\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    #Once image is opened make copies of unedited image and array to use later on\n",
    "    #make copy of original unadultorated image\n",
    "    im_orig = im.copy()\n",
    "    #Make an array of the unadultorate image\n",
    "    im_orig_array = np.array(im_orig)\n",
    "    #Set the number formatting to unit8 for compatability with other packages\n",
    "    im_orig_array = im_orig_array.astype(\"uint8\")\n",
    "    \n",
    "    #create plot of convoluted and binarised image\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(im_orig_array, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'raw_image.png', dpi=300)\n",
    "            \n",
    "    #As there may be a fair amount of noise in the background image select a region from the image which has nothing of interest in it\n",
    "    #This selected region is then used to find an average pixel value in the background region which will be subtracted from the image array\n",
    "    bg_x1 = round((0.90*im_orig_array.shape[1]))\n",
    "    bg_x2 = round((0.99*im_orig_array.shape[1]))\n",
    "    bg_y1 = round((0.90*im_orig_array.shape[0]))\n",
    "    bg_y2 = round((0.99*im_orig_array.shape[0]))\n",
    "    \n",
    "    #Print out background region idecies that are to be used for background noise reduction\n",
    "    # print(bg_x1)\n",
    "    # print(bg_x2)\n",
    "    # print(bg_y1)\n",
    "    # print(bg_y2)\n",
    "    \n",
    "    #Slice out the selected region    \n",
    "    bg_select = im_orig_array[bg_y1:bg_y2,bg_x1:bg_x2]\n",
    "    \n",
    "    #create plot selected image background\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(bg_select, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'_bg_select.png', dpi=300)\n",
    "    \n",
    "    #Having cut out the background region convert the 2D array into a 1D  \n",
    "    bg_med = bg_select.flatten()\n",
    "\n",
    "    #Calculate the median and mean average values of the background region\n",
    "    bg_select_med = np.median(bg_med)+2*np.std(bg_med)  \n",
    "    bg_select_mean = np.mean(bg_med)+2*np.std(bg_med)\n",
    "    \n",
    "    #Make a copy of the original image array\n",
    "    im_orig_array_c = im_orig_array.copy()\n",
    "    \n",
    "    #Any pixel in the image which is less than the mean pixel value of the background region is to be set to zero i.e. made blank \n",
    "    im_orig_array_c[im_orig_array_c < bg_select_mean] = 0\n",
    "    \n",
    "    #create plot selected image background\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(im_orig_array_c, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'_thresh_bg_select.png', dpi=300)\n",
    "           \n",
    "    #Convert the background subtracted array back into an image that may be evaluated with pillow package\n",
    "    im = Image.fromarray(im_orig_array_c)\n",
    "    \n",
    "    #create plot selected image background\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(im_orig_array_c, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'im_debug.png', dpi=300)\n",
    "\n",
    "    #trim image to just pixels of interest using trim2 as defined above\n",
    "    fibre_box,fpadding = trim2(im,(fibre_pad*2),trim_offset)\n",
    "    im = im.crop(fibre_box)\n",
    "    \n",
    "    #convert trimmed image into array from pillow image\n",
    "    nim =  np.array(im)\n",
    "    #make copy of trimmed image to be used later on if needed\n",
    "    nim_copy = nim.copy()\n",
    "    \n",
    "    #create plot of convoluted and binarised image\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(nim_copy, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'cropped_image.png', dpi=300)\n",
    "    \n",
    "    #Reduce image size to minimise the time associated with the processing of each image\n",
    "    nim = rescale(nim, fibre_scale, anti_aliasing=False)\n",
    "    #Convert the number format of all values in array to that of unit8 with range from 0-255 to conform with package standards\n",
    "    nim = np.uint8(nim * 255)\n",
    "            \n",
    "############################################################################################################################################################ \n",
    "                                                ### OUTER WALL DETECTION  ###\n",
    "############################################################################################################################################################\n",
    "    \n",
    "    ##As want to find the length of connected pixels first blur the image so that missed regions otherwise lost from binarisation may be considered\n",
    "    #Set the size of the filter to 7x7 pixels\n",
    "    x = 7\n",
    "    y = 7\n",
    "    #Applying GayssuanBlur to fill gaps in image caused by binarisation\n",
    "    nim = cv2.GaussianBlur(nim,(x,y),0)\n",
    "    #Apply OTSU's binarisation method to strip away as much noise as possible and convert image into binary\n",
    "    ret,fibre_thresh = cv2.threshold(nim,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    \n",
    "    #Set the size of the screen used when convolving image\n",
    "    x = 2\n",
    "    y = 2\n",
    "    #Mark all pixels such that there are at least 1 pixels in their 2x2 neighborhood\n",
    "    nim = signal.convolve2d(fibre_thresh,np.ones((x,y), dtype=int), mode='same')\n",
    "    \n",
    "    #create plot of convoluted and binarised image\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(nim, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'convolve2d_image.png', dpi=300)\n",
    "\n",
    "    #Need to find overall orientation of image and rotate to make horizontal\n",
    "    #To initially find orientation to trim image to leave behind only narrow region of interest this must be in both the x and y axis\n",
    "    #to ensure this is only done for first image make if gate to prevent multi runs\n",
    "    #Make place holder for the whether the image needs to be rotated or not\n",
    "    coords = 0 \n",
    "    if img_no == 0:\n",
    "        #get location of all detected true pixels\n",
    "        coords = np.column_stack(np.where(nim == 255))\n",
    "        #consider the spread of data in each direction, as considering flat membranes expect smaller spread in direction of normal to the face of the membrane\n",
    "        #find the IQR in x_axis\n",
    "        iqr_x = iqr(coords[:,0])\n",
    "        #find the median in the x-axis\n",
    "        median_x = np.median(coords[:,0])\n",
    "        #find the IQR in y_axis\n",
    "        iqr_y = iqr(coords[:,1])\n",
    "        #If there is more of a spread in the number of filled pixels one direction of the other rotate the image to set the minimum spread in the x axis\n",
    "        if iqr_x < iqr_y:\n",
    "            #make note to rotate\n",
    "            rotate = 1\n",
    "\n",
    "    #If the image is to be rotated then\n",
    "    if rotate == 1:    \n",
    "        #rotate the image\n",
    "        nim = nim.swapaxes(-2,-1)[...,::-1]\n",
    "        #get location of all detected true pixels\n",
    "        coords = np.column_stack(np.where(nim == 255))\n",
    "        #reconsier the median of the x axis as that previously of the y axis due to rotation\n",
    "        median_x = np.median(coords[:,0])\n",
    "        #reconsider IQR as well\n",
    "        iqr_x = iqr(coords[:,0])\n",
    "    \n",
    "        \n",
    "        \n",
    "    #create plot of convoluted and binarised image\n",
    "    if debug == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(nim, 'gray')\n",
    "        if save_pic == True:\n",
    "            ax.figure.savefig(save_loc+filename+'rotated_convolve2d_image.png', dpi=300)\n",
    "\n",
    "    #Covert list of coordinates into pandas dataframe\n",
    "    coords = pd.DataFrame(coords)\n",
    "    #get unique y-axis points at which pixels are detected\n",
    "    unique_vals = pd.unique(coords[0].values)\n",
    "    \n",
    "    #Make list to hold all of the membrane thicknesses\n",
    "    thicknesses = []\n",
    "    \n",
    "    #Itterating through each of the unique y-axis points\n",
    "    for i in unique_vals:\n",
    "        #isolate only the data associated with y-axis\n",
    "        temp = coords.loc[coords[0] == i][1]\n",
    "        #Find the median and IQR of each line\n",
    "        Q1 = temp.quantile(0.25)\n",
    "        Q3 = temp.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        median = temp.quantile(0.5)\n",
    "        #convert temp from series to list\n",
    "        temp = temp.tolist()\n",
    "        #remove any values from temp which are more than 2 IQR from median\n",
    "        temp = [x if abs(x-median)<(2*IQR) else median for x in temp]\n",
    "        #find how thick membrane is at each y axis point\n",
    "        if max(temp)-min(temp) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            thicknesses.append(max(temp)-min(temp))\n",
    "    \n",
    "    #Convert list of thicknesses to an array so that stats may be determined\n",
    "    thicknesses = np.array(thicknesses)\n",
    "    #Calculate the stats associated with membrane thicknesses\n",
    "    thick_mean = np.mean(thicknesses)*(1/fibre_scale)*pxum\n",
    "    thick_med = (np.median(thicknesses)/fibre_scale)*pxum\n",
    "    q75, q25 = (np.percentile(thicknesses, [75 ,25])/fibre_scale)*pxum\n",
    "    thick_IQR = q75 - q25\n",
    "    \n",
    "    \n",
    "############################################################################################################################################################ \n",
    "                                        ### Return membrane stats  ###\n",
    "############################################################################################################################################################\n",
    "    return (thick_mean,thick_med,thick_IQR,rotate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate membrane properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/7hyg5yn15331npl8_ss6cl_40000gn/T/ipykernel_2035/1193030535.py:24: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for filename in tqdm_notebook(files):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd06631463f4c6bb0956e5963d61756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         filename  thick_IQR  thick_mean  thick_med\n",
      "0  S4_50PPM_8HRS_5PX__rec0002.tif       40.0  150.851064      160.0\n",
      "1  S4_50PPM_8HRS_5PX__rec0003.tif       20.0  147.741935      160.0\n",
      "2  S4_50PPM_8HRS_5PX__rec0004.tif       40.0  154.594595      160.0\n",
      "3  S4_50PPM_8HRS_5PX__rec0005.tif       40.0  155.957447      160.0\n",
      "4  S4_50PPM_8HRS_5PX__rec0006.tif       40.0  149.723757      160.0\n"
     ]
    }
   ],
   "source": [
    "#If you want to run the code make sure this is true (this is here just to prevent accidently starting the code)\n",
    "Run = True\n",
    "#Through out the code there are the options to save out figures of each of the steps taken. These may be used for illustration purposes or to debug \n",
    "show_all = False\n",
    "#Debug prints will return various metrics from throughout the code to help understand why errors may be occouring\n",
    "debug_print = False\n",
    "\n",
    "#Set constant values used within the image analysis - \n",
    "#How many um does each pixel represent?\n",
    "pxum = 5\n",
    "#How many pixels should be added as a buffer to the image after carrying out the initial trim\n",
    "fibre_pad = 50\n",
    "#What scale should be used when reducing image size. Note that lower scale is faster but may increase error\n",
    "fibre_scale = 0.25\n",
    "#What off set value should be subtracted from the background to minimise noise?\n",
    "trim_offset = -80\n",
    "\n",
    "\n",
    "#If you want to run the code \n",
    "if Run == True:\n",
    "    \n",
    "    #Set column names of the output dataframe\n",
    "    columns = ['filename','thick_IQR','thick_mean','thick_med']\n",
    "    #Make dataframe to hold all calculated metrics of memebranes evaluated\n",
    "    cfp = pd.DataFrame(columns = columns)\n",
    "    \n",
    "    #Generate list of all images that are to be evaluated in data location\n",
    "    files = [x for x in os.listdir(data_loc) if x.endswith(('.tif','.jpg','.png','.bmp'))==True and x.startswith('._')==False]\n",
    "    \n",
    "    #Make counter for file number\n",
    "    img_no = -1\n",
    "    #Place holder as to if the image should be rotated or not? 0 is no 1 is yes\n",
    "    rotate = 0\n",
    "    #Itterating through files in data location with tqdm you get a nice progress bar and estimate of how long the program will take to run\n",
    "    for filename in tqdm_notebook(files):     \n",
    "        #proceed image count\n",
    "        img_no = img_no+1 \n",
    "        #acertain fibre properties as defined above\n",
    "        if show_all == True:\n",
    "            print(filename) #This is good to be kept on incase crashes on particular image - can then debug on that specific image\n",
    "            flatmem_properties = fibrefeature(data_loc,filename,pxum,fibre_pad,fibre_scale,img_no,rotate,True,True,True)\n",
    "        else:\n",
    "            # print(filename)\n",
    "            flatmem_properties = fibrefeature(data_loc,filename,pxum,fibre_pad,fibre_scale,img_no,rotate,False,False,False)\n",
    "        #If so some reason the program bugs and does not return data for a given image allow the program to continue to run rather than crash.\n",
    "        if flatmem_properties is None:\n",
    "            pass\n",
    "        else:\n",
    "            #Bring update the rotate value so that it does not have to be evaluated each time as this should be the same for all images within a set\n",
    "            rotate = flatmem_properties[3]\n",
    "            #Copy evaluated membrane metrics to the summary dataframe\n",
    "            cfp = cfp.append({'filename':filename,'thick_mean':flatmem_properties[0],'thick_med':flatmem_properties[1],'thick_IQR':flatmem_properties[2]}, ignore_index=True)\n",
    "    #Once has completed print out the top of the summary dataframe as this can be used as a quick sanity check before continuing\n",
    "    print(cfp.head())\n",
    "    #Save the summary dataframe out as a CSV to be processed further later one - important so you dont have to run the image processing each time\n",
    "    cfp.to_csv(save_loc+savename+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/flat_sheet/output/processed_flat.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dw/7hyg5yn15331npl8_ss6cl_40000gn/T/ipykernel_2035/4086339558.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Initially open processed data csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprocessed_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_loc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'processed_flat.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#For each of the rows in the processed data csv file match the corresponding sample file to associated metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessed_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/ristomartin/OneDrive/Dropbox/UniStuff/DPhil/Experimental/python_analysis/uCT/flat_sheet/output/processed_flat.csv'"
     ]
    }
   ],
   "source": [
    "#Initially open processed image data csv file\n",
    "processed_flat = pd.read_csv(save_loc + 'processed_flat.csv',index_col = 0)\n",
    "\n",
    "#For each of the rows in the processed data csv file match the corresponding sample file to associated metadata\n",
    "for file, row in processed_flat.iterrows():\n",
    "    #For each of row of data add the associated metadata\n",
    "    #Get pyridine concentration used\n",
    "    processed_flat.loc[file, 'pyridine_conc'] = sample_key.loc[sample_key['uCT_filename'] == file, 'pyridine_conc'].iloc[0]\n",
    "    #Get rotation speed used\n",
    "    processed_flat.loc[file, 'rotation_speed'] = sample_key.loc[sample_key['uCT_filename'] == file, 'rotation_speed'].iloc[0]\n",
    "    #Get the name of the polymer solution used\n",
    "    processed_flat.loc[file, 'solution_name'] = sample_key.loc[sample_key['uCT_filename'] == file, 'solution_name'].iloc[0]\n",
    "    #Get the amount of time used to spin each of the membranes\n",
    "    processed_flat.loc[file, 'time_spun'] = sample_key.loc[sample_key['uCT_filename'] == file, 'time_spun'].iloc[0]\n",
    "    #Get the voltage used\n",
    "    voltage = sample_key.loc[sample_key['uCT_filename'] == file, 'voltage'].iloc[0]\n",
    "    #Get the minimum voltage at which a taylor cone would form on the day of the spin\n",
    "    min_voltage = sample_key.loc[sample_key['uCT_filename'] == file, 'min_voltage'].iloc[0]\n",
    "    #Get the maximum voltage at which a taylor cone would form on the day of the spin\n",
    "    max_voltage = sample_key.loc[sample_key['uCT_filename'] == file, 'max_voltage'].iloc[0]\n",
    "    #Evaluate the range of the voltage at whicht a taylor cone would form on the day of the spin\n",
    "    processed_flat.loc[file, 'Voltage Range'] = (((voltage-min_voltage)/(max_voltage-min_voltage))*100).round(0)\n",
    "#Having collated all the meta data check correctly recorded\n",
    "print(processed_flat.head())\n",
    "#save pandas data frame of all processed image data with assciated metadata as CSV\n",
    "processed_flat.to_csv(save_loc + 'processed_flat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initially import processed flat sheet membrane data along with metadata\n",
    "processed_flat = pd.read_csv(save_loc + 'processed_flat.csv',index_col = 0)\n",
    "\n",
    "#FCeate figure for new plot\n",
    "fig, ax = plt.subplots()\n",
    "                \n",
    "#Before able to plot need to catagorise data by variable e.g by pyridine conc\n",
    "#as all data is in a single column and are only plotting a line graph can separate series using pandas groupby\n",
    "for key, grp in processed_flat.sort_values(['time_spun']).groupby(['pyridine_conc']):\n",
    "    \n",
    "    #set the data in each axis\n",
    "    x = grp['time_spun']\n",
    "    y = grp['median_thickness_um']\n",
    "\n",
    "    ax.plot(x,y, label = key)\n",
    "    #add precalculated IQR bands for each graph for force/extension line graph\n",
    "    ax.fill_between(grp['time_spun'], grp['median_thickness_um'] - grp['thickness_IQR_um'],grp['median_thickness_um'] + grp['thickness_IQR_um'], alpha=0.35)\n",
    "\n",
    "#adding formatting into each graph\n",
    "xlabel = 'Time Spun (Hrs)'\n",
    "ylabel = 'Median Membrane Thickness ($\\mu$m)'\n",
    "ax.legend()\n",
    "ax.set(xlabel=xlabel, ylabel= ylabel) #(xlabel=x, ylabel='Fibre Diameter ($\\mu$m)')\n",
    "\n",
    "#save figure out\n",
    "fig.savefig(save_loc+'flat_thickness.png',bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
